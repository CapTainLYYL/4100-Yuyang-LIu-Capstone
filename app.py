import streamlit as st
from openai import OpenAI
import json
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title="WRTT Assistant")
st.title("ğŸ’¬ WRTT Assistant")

# åˆå§‹åŒ–ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿
DEFAULT_SYSTEM_PROMPT = """Backgounds:1.You are an AI documentation assistant for WRTT company. 
2.Regardless of the user's language, you must answer in English.
3.Your thinking process must always be in English."""

# åœ¨ä¾§è¾¹æ æ·»åŠ é…ç½®é€‰é¡¹
with st.sidebar:
    # APIå¯†é’¥è¾“å…¥
    openai_api_key = st.text_input("API Key", key="chatbot_api_key", type="password")
    "[Get API key](https://platform.siliconflow.cn/api_keys)"
    
    # ç”¨æˆ·è®¾ç½®åŒºåŸŸ
    with st.expander("Settings", expanded=False):
        # æç¤ºè¯æ¨¡æ¿é…ç½®
        st.subheader("Prompt Template")
        system_prompt = st.text_area(
            "System Prompt",
            value=DEFAULT_SYSTEM_PROMPT,
            key="system_prompt"
        )
    
    # å¯¹è¯ç®¡ç†
    if st.button("New Chat"):
        # ä¿å­˜å½“å‰å¯¹è¯åˆ°å†å²è®°å½•
        if "messages" in st.session_state:
            if "history_conversations" not in st.session_state:
                st.session_state.history_conversations = []
            
            # å¦‚æœå½“å‰å¯¹è¯å·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™æ·»åŠ æ–°å¯¹è¯
            if st.session_state.current_chat_index < len(st.session_state.history_conversations):
                st.session_state.history_conversations[st.session_state.current_chat_index] = st.session_state.messages.copy()
            else:
                st.session_state.history_conversations.append(st.session_state.messages.copy())
        
        # åˆ›å»ºæ–°å¯¹è¯å¹¶æ·»åŠ åˆ°å†å²è®°å½•
        new_messages = [
            {"role": "system", "content": system_prompt},
            {"role": "assistant", "content": "How can I assist you with WRTT documentation today?"}
        ]
        st.session_state.history_conversations.append(new_messages.copy())
        st.session_state.current_chat_index = len(st.session_state.history_conversations) - 1
        st.session_state.messages = new_messages.copy()

    # å†å²å¯¹è¯åˆ—è¡¨
    st.subheader("Chat History")
    if "history_conversations" in st.session_state:
        for idx in range(len(st.session_state.history_conversations)):
            if st.button(f"Chat {idx + 1}", key=f"load_conv_{idx}"):
                st.session_state.current_chat_index = idx
                st.session_state.messages = st.session_state.history_conversations[idx].copy()

# åˆå§‹åŒ–APIå®¢æˆ·ç«¯
if not openai_api_key:
    try:
        openai_api_key = st.secrets.api_key
    except AttributeError:
        st.info("Please enter your API key")
        st.stop()

client = OpenAI(
    api_key=openai_api_key,
    base_url="https://api.siliconflow.cn/v1/"
)
knowledge_base = [
    {"question": "What services does WRTT provide in wealth management?", "answer": "WRTT provides personalized investment strategies, portfolio management, and financial planning services."},
    {"question": "How do I open a retirement account?", "answer": "You can open a retirement account by contacting a WRTT advisor or visiting the Wells Fargo website and selecting the retirement account that fits your needs."},
    {"question": "What is a trust and how does it work?", "answer": "A trust is a legal arrangement where a trustee manages assets on behalf of beneficiaries. It helps in estate planning and asset protection."},
    {"question": "How can I check my 401k balance?", "answer": "Log into your Wells Fargo online account and navigate to the Retirement section to view your 401(k) balance."},
    {"question": "What are the fees associated with wealth management services?", "answer": "Fees vary based on services used, typically including management fees, fund expenses, and sometimes transaction fees."},
    {"question": "Can I rollover my old 401k into an IRA?", "answer": "Yes, you can rollover a 401(k) into a Wells Fargo IRA. This typically involves contacting a retirement advisor and filling out a rollover form."},
    {"question": "What is the 401k contribution limit for 2024?", "answer": "For 2024, the IRS contribution limit is $22,500, or $30,000 if you're 50 or older (including catch-up contributions)."},
    {"question": "How secure are my investments with WRTT?", "answer": "WRTT employs industry-standard security protocols and is FDIC-insured where applicable, ensuring your investments are safe."},
    {"question": "What is the difference between a Roth and Traditional IRA?", "answer": "Traditional IRAs offer tax-deferred growth while Roth IRAs provide tax-free withdrawals in retirement."},
    {"question": "How do I contact a trust advisor?", "answer": "You can reach a trust advisor by calling the WRTT customer service or visiting a local branch for a scheduled appointment."}
]

knowledge_context = "Knowledge Base:\n"
for qa in knowledge_base:
    knowledge_context += f"Q: {qa['question']}\nA: {qa['answer']}\n\n"
# åˆå§‹åŒ–å¯¹è¯å†å²
if "history_conversations" not in st.session_state:
    initial_messages = [
        {"role": "system", "content": system_prompt},
        {"role": "assistant", "content": "How can I assist you with WRTT documentation today?"}
    ]
    st.session_state.history_conversations = [initial_messages.copy()]
    st.session_state.current_chat_index = 0

if "messages" not in st.session_state:
    st.session_state.messages = st.session_state.history_conversations[st.session_state.current_chat_index].copy()

# æ˜¾ç¤ºå¯¹è¯å†å²ï¼ˆè¿‡æ»¤ç³»ç»Ÿæ¶ˆæ¯ï¼‰
for msg in st.session_state.messages:
    if msg["role"] != "system":
        st.chat_message(msg["role"]).write(msg["content"])


# å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input():
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)

    # åŠ è½½çŸ¥è¯†åº“
    knowledge_base = []
    try:
        with open("knowledge_base.json", "r", encoding="utf-8") as f:
            knowledge_base = json.load(f)
    except Exception as e:
        st.error(f"Failed to load knowledge base: {str(e)}")

    # RAGå¤„ç†æµç¨‹
    context = ""
    if knowledge_base:
        # è·å–Embeddings
        def get_embedding(text):
            response = client.embeddings.create(
                model="BAAI/bge-large-en-v1.5",
                input=text
            )
            return np.array(response.data[0].embedding)

        try:
            # è®¡ç®—ç”¨æˆ·è¾“å…¥å‘é‡
            user_embedding = get_embedding(prompt)
            
            # è®¡ç®—çŸ¥è¯†åº“æ–‡æ¡£å‘é‡
            doc_embeddings = []
            for doc in knowledge_base:
                content = f"Q: {doc.get('question','')}\nA: {doc.get('answer','')}"
                doc_embeddings.append(get_embedding(content))
            
            # è®¡ç®—ç›¸ä¼¼åº¦
            similarities = cosine_similarity([user_embedding], doc_embeddings)[0]
            top_indices = np.argsort(similarities)[-3:][::-1]

            # æ„å»ºä¸Šä¸‹æ–‡
            context = "Your answer must strictly follow the given knowledge base answers, first give the content in the knowledge base, then start a new paragraph to supplement: \n"
            context = "Relevant knowledge base content:\n"
            for idx in top_indices:
                context += f"Q: {knowledge_base[idx].get('question','')}\nA: {knowledge_base[idx].get('answer','')}\n"

        except Exception as e:
            st.error(f"Knowledge retrieval failed: {str(e)}")

    # æ„å»ºAPIè¯·æ±‚æ¶ˆæ¯
    messages_for_api = [
        {"role": "system", "content": f"{system_prompt}\n{knowledge_context}\n{context}"},
        *[msg for msg in st.session_state.messages if msg["role"] != "system"]
    ]
    print(messages_for_api)
    # è°ƒç”¨API
    try:
        response = client.chat.completions.create(
            model="deepseek-ai/DeepSeek-V3",
            messages=messages_for_api,
            stream=True,
            extra_body={
                "reasoning_config": {
                    "enabled": True,
                    "type": "compact"
                }
            }
        )
    except Exception as e:
        st.error(f"API call failed: {str(e)}")
        st.stop()

    # æµå¼å¤„ç†å“åº”
    assistant_reply = ""
    reasoning_process = ""
    with st.chat_message("assistant"):
        reply_placeholder = st.empty()
        reasoning_expander = st.expander("Thinking Process", expanded=False)
        reasoning_placeholder = reasoning_expander.empty()

        # åˆå§‹åŒ–ä¸´æ—¶æ˜¾ç¤ºå˜é‡
        current_display = ""
        current_reasoning = ""

        for chunk in response:
            # å®‰å…¨æ ¡éªŒå±‚1ï¼šç¡®ä¿æœ‰æœ‰æ•ˆchoices
            if not chunk.choices:
                continue

            choice = chunk.choices[0]
            
            # å®‰å…¨æ ¡éªŒå±‚2ï¼šè·å–deltaå¯¹è±¡
            delta = getattr(choice, 'delta', None)
            if not delta:
                continue

            # å¤„ç†ä¸»å›å¤å†…å®¹
            content = getattr(delta, 'content', None) or ""
            if content:
                assistant_reply += content
                current_display = assistant_reply + "â–Œ"  # å¸¦å…‰æ ‡
                reply_placeholder.markdown(current_display)

            # å¤„ç†æ€è€ƒè¿‡ç¨‹
            reasoning_content = getattr(delta, 'reasoning_content', None) or ""
            if reasoning_content:
                reasoning_process += reasoning_content
                current_reasoning = reasoning_process + "â–Œ"
                with reasoning_expander:
                    reasoning_placeholder.markdown(current_reasoning)

        # æœ€ç»ˆæ¸…ç†å…‰æ ‡ç¬¦å·
        final_display = assistant_reply.replace("â–Œ", "")
        final_reasoning = reasoning_process.replace("â–Œ", "")
        
        reply_placeholder.markdown(final_display)
        with reasoning_expander:
            reasoning_placeholder.markdown(final_reasoning)

    # æ›´æ–°å¯¹è¯å†å²
    st.session_state.messages.append({
        "role": "assistant",
        "content": assistant_reply,
        "reasoning": reasoning_process  # å¯é€‰å­˜å‚¨æ€è€ƒè¿‡ç¨‹
    })
    st.session_state.history_conversations[st.session_state.current_chat_index] = st.session_state.messages.copy()